{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Self-Attention Fro All The Inputs"
      ],
      "metadata": {
        "id": "SDStHKbNKaQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the following input sentence:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Thnttt3u21DC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nws5YEHL1TJs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "[[0.43, 0.15, 0.89], # x1\n",
        "[0.55, 0.87, 0.66], # x2\n",
        "[0.57, 0.85, 0.64],  # x3\n",
        "[0.22, 0.58, 0.33], # x4\n",
        "[0.77, 0.25, 0.10],# x5\n",
        "[0.05, 0.80, 0.55]] # x6\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we add an additional for-loop to\n",
        "compute the dot products for all pairs of inputs."
      ],
      "metadata": {
        "id": "hgEahh2lPtiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty(6, 6)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "J-Q2Q_fCP0aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each element in the preceding tensor represents an attention score between\n",
        "each pair of inputs. Note that the values are normalized, which is why they differ from the unnormalized\n",
        "attention scores in the preceding tensor. We will take care of the\n",
        "normalization later."
      ],
      "metadata": {
        "id": "e2emppSYQG7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When computing the preceding attention score tensor, we used for-loops in\n",
        "Python. However, for-loops are generally slow, and we can achieve the same\n",
        "results using matrix multiplication:"
      ],
      "metadata": {
        "id": "bGpKE9YqQUdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "JkCXVtnBQSa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we now normalize each row so that the\n",
        "values in each row sum to 1:"
      ],
      "metadata": {
        "id": "4K1M9WCuQpcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "X7Z1m3a6Qrwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we now use these attention weights to compute all\n",
        "context vectors via matrix multiplication:"
      ],
      "metadata": {
        "id": "aVVlVa9WRY5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "id": "0hxx_D5IQrr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQCynC2gQrmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E3F9RJr3Qrdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}