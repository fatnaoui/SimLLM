### Implementing a GPT model from Scratch To Generate Text
-----------------------------------------------------------
This chapter covers:
- Coding a GPT-like large language model (LLM) that can be trained to generate
human-like text.

- Normalizing layer activations to stabilize neural network training.
Adding shortcut connections in deep neural networks to train models more
effectively.

- Computing the number of parameters and storage requirements of GPT
models.
